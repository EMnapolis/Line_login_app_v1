#utility.py
import streamlit as st
import os
import sqlite3
import pandas as pd
from io import StringIO
from io import BytesIO
from openai import OpenAI
from datetime import datetime
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import TextLoader
from langchain.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from charset_normalizer import from_bytes
from dotenv import load_dotenv
import tiktoken
import json
#==== import libary ====

#==== global path ====
db_folder = os.path.join("data")
db_path = os.path.join("data", "sqdata.db")
schema_path = os.path.join("data", "schema.sql")
user_id = st.session_state.get("user_id")
#==== global path ====

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å config.py ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ os.getenv() ‡πÄ‡∏≠‡∏á
from config import OPENAI_API_KEY, CHAT_TOKEN

# ===== OpenAI Client =====
client = OpenAI(api_key=OPENAI_API_KEY)

# ===== ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• SQLite =====
def init_db():
    if not os.path.exists(db_folder):
        os.makedirs(db_folder)

    first_time = not os.path.exists(db_path)
    conn = sqlite3.connect(db_path, check_same_thread=False)
    
    if first_time:
        initialize_schema(conn)
        
    return conn, conn.cursor()

# ===== ‡πÇ‡∏´‡∏•‡∏î schema.sql ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á =====
def initialize_schema(conn, schema_path=schema_path):
    """
    ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô SQL schema ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .sql ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏
    """
    if not os.path.exists(schema_path):
        raise FileNotFoundError(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå schema: {schema_path}")
    
    with open(schema_path, "r", encoding="utf-8") as f:
        sql_script = f.read().strip()

    if not sql_script:
        raise ValueError("‚ö†Ô∏è ‡πÑ‡∏ü‡∏•‡πå schema ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")

    try:
        conn.executescript(sql_script)
        conn.commit()
        print("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á schema ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á schema: {e}")

# ===== ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• =====
def save_conversation_if_ready(conn, cursor, messages_key, source="chat_gpt", **token_usage):
    messages = st.session_state.get(messages_key, [])
    conv_key = f"conversation_id_{messages_key}"
    last_key = f"last_saved_count_{messages_key}"

    conv_id = st.session_state.get(conv_key)
    last_saved_count = st.session_state.get(last_key, 0)

    if len(messages) >= 2 and len(messages) > last_saved_count:
        last_two = messages[-2:]
        if last_two[0]["role"] == "user" and last_two[1]["role"] == "assistant":

            if conv_id is None:
                title = generate_title_from_conversation(messages)
                cursor.execute("""
                    INSERT INTO conversations (user_id, title, source, 
                        prompt_tokens, completion_tokens, total_tokens)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    st.session_state["user_id"],
                    title,
                    source,
                    token_usage.get("prompt_tokens"),
                    token_usage.get("completion_tokens"),
                    token_usage.get("total_tokens")
                ))
                conv_id = cursor.lastrowid
                st.session_state[conv_key] = conv_id

            for msg in messages[last_saved_count:]:
                cursor.execute("""
                    INSERT INTO messages (
                        user_id, conversation_id, role, content,
                        prompt_tokens, completion_tokens, total_tokens
                    )
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    st.session_state["user_id"],
                    conv_id,
                    msg.get("role", "user"),
                    msg.get("content", ""),
                    msg.get("prompt_tokens"),
                    msg.get("completion_tokens"),
                    msg.get("total_tokens"),
                ))
                message_id = cursor.lastrowid

                # ‚úÖ ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡πá‡∏ö conversation_id ‡∏Å‡∏±‡∏ö message_id ‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å
                if "response_json" in msg:
                    cursor.execute("""
                        INSERT INTO raw_json (conversation_id, message_id, response_json)
                        VALUES (?, ?, ?)
                    """, (
                        conv_id,
                        message_id,
                        msg["response_json"]
                    ))

            conn.commit()
            st.session_state[last_key] = len(messages)
            st.toast(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å {source}")
def send_prompt_to_gpt(prompt_text, message_key, model="gpt-3.5-turbo"):
    messages = st.session_state.get(message_key, [])
    messages.append({"role": "user", "content": prompt_text})

    response = client.chat.completions.create(
        model=model,
        messages=messages
    )

    reply = response.choices[0].message.content
    usage = response.usage

    messages.append({
        "role": "assistant",
        "content": reply,
        "prompt_tokens": usage.prompt_tokens,
        "completion_tokens": usage.completion_tokens,
        "total_tokens": usage.total_tokens
    })

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ session
    st.session_state[message_key] = messages

    return reply, usage

# ===== ‡πÉ‡∏ä‡πâ AI ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏ö‡∏ö‡∏¢‡πà‡∏≠ =====
def generate_title_from_conversation(messages):
    try:
        system_prompt = {"role": "system", "content": "You are an assistant that summarizes the topic of a conversation in 5-10 Thai words."}
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[system_prompt] + messages + [{"role": "user", "content": "‡∏™‡∏£‡∏∏‡∏õ‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ç‡∏≠‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ô‡∏µ‡πâ‡∏™‡∏±‡πâ‡∏ô ‡πÜ"}]
        )
        return response.choices[0].message.content.strip()
    except Exception:
        return "‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà" if not messages else messages[0].get("content", "‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà")[:30]

# ===== ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ =====
def list_conversations(user_id=None):
    db_path = os.path.join("data", "sqdata.db")
    conn = sqlite3.connect(db_path, check_same_thread=False)

    # ‡πÄ‡∏û‡∏¥‡πà‡∏° token columns
    query = """
        SELECT id, user_id, title, source,
               prompt_tokens, completion_tokens, total_tokens,
               created_at
        FROM conversations
    """
    params = ()

    if user_id:
        query += " WHERE user_id = ?"
        params = (user_id,)

    query += " ORDER BY created_at DESC"
    df = pd.read_sql_query(query, conn, params=params)
    conn.close()
    return df.values.tolist()

# ===== ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏≤‡∏£‡∏≤‡∏á Prompt =====
def init_prompt_table():
    conn = sqlite3.connect(db_path, check_same_thread=False)
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS prompts (
            prompt_name TEXT,
            user_id TEXT NOT NULL,
            content TEXT,
            prompt_tokens INTEGER,
            completion_tokens INTEGER,
            total_tokens INTEGER,
            PRIMARY KEY (prompt_name, user_id)
        )
    """)
    conn.commit()
def save_prompt(prompt_name, content):
    user_id = st.session_state.get("user_id")
    if not user_id:
        st.warning("‚õî ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö")
        return
    conn = sqlite3.connect(db_path, check_same_thread=False)
    cursor = conn.cursor()
    cursor.execute("""
        REPLACE INTO prompts (prompt_name, user_id, content, prompt_tokens, completion_tokens, total_tokens)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (prompt_name, user_id, content, 0, 0, 0))  # ‡∏õ‡∏£‡∏±‡∏ö token = 0 ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ö parameter ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    conn.commit()
    conn.close()
def list_prompts():
    user_id = st.session_state.get("user_id")
    role = st.session_state.get("Role", "user")

    conn = sqlite3.connect(db_path, check_same_thread=False)
    cursor = conn.cursor()

    if role == "admin":
        cursor.execute("SELECT prompt_name, content FROM prompts ORDER BY prompt_name")
    else:
        cursor.execute("SELECT prompt_name, content FROM prompts WHERE user_id = ? ORDER BY prompt_name", (user_id,))
    results = cursor.fetchall()
    conn.close()
    return results
def delete_prompt(name):
    user_id = st.session_state.get("user_id")
    role = st.session_state.get("Role", "user")

    conn = sqlite3.connect(db_path, check_same_thread=False)
    cursor = conn.cursor()

    if role == "admin":
        cursor.execute("DELETE FROM prompts WHERE prompt_name = ?", (name,))
    else:
        cursor.execute("DELETE FROM prompts WHERE prompt_name = ? AND user_id = ?", (name, user_id))

    conn.commit()
    conn.close()

## ============================== ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå ==============================
# ===== ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö encoding ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° =====
def try_decode_file(file_bytes: bytes) -> str:
    """‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏õ‡∏•‡∏á byte ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö encoding"""
    try:
        result = from_bytes(file_bytes).best()
        if result:
            return str(result)
    except Exception:
        pass

    try:
        return file_bytes.decode("utf-8")
    except UnicodeDecodeError:
        return file_bytes.decode("iso-8859-1", errors="replace")
# ===== ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á RAG Chain =====
def process_file_to_chain(uploaded_file):
    """‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á RAG Chain ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏ï‡πâ‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"""
    if not uploaded_file:
        st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Å‡πà‡∏≠‡∏ô")
        return

    with st.spinner("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå..."):
        try:
            file_bytes = uploaded_file.read()
            file_content = try_decode_file(file_bytes)

            st.text_area("üìñ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤", file_content[:1000], height=200, disabled=True)

            doc = Document(page_content=file_content)
            splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            chunks = splitter.split_documents([doc])

            embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
            vectorstore = Chroma.from_documents(chunks, embeddings)

            chain = ConversationalRetrievalChain.from_llm(
                llm=ChatOpenAI(temperature=0, openai_api_key=OPENAI_API_KEY),
                retriever=vectorstore.as_retriever(),
                memory=ConversationBufferMemory(memory_key="chat_history", return_messages=True),
            )

            # ‚úÖ ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏ß‡πâ‡πÉ‡∏ô session
            st.session_state["chain"] = chain
            st.session_state["chat_history"] = []
            st.session_state["file_content"] = file_content

            st.success("‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô! ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢")

        except Exception as e:
            st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
# ===== üîé ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î =====
def read_uploaded_file(file_name, file_bytes):
    """‡πÉ‡∏ä‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó"""
    file_name = file_name.lower()
    if file_name.endswith(".xlsx"):
        df = pd.read_excel(BytesIO(file_bytes))
        return df.to_string(index=False)
    elif file_name.endswith(".csv"):
        df = pd.read_csv(BytesIO(file_bytes))
        return df.to_string(index=False)
    else:
        result = from_bytes(file_bytes).best()
        return str(result) if result else file_bytes.decode("utf-8")
# ===== üí¨ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏á‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó =====
def append_chat(role, content, state_key="chat_history"):
    """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏á‡πÉ‡∏ô session chat"""
    st.chat_message(role).write(content)
    st.session_state.setdefault(state_key, []).append({
        "role": role,
        "content": content
    })
# ===== ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô Document ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM =====
def get_split_docs(uploaded_file):
    """‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ Document ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß"""
    file_name = uploaded_file.name.lower()

    if file_name.endswith(".xlsx"):
        df = pd.read_excel(uploaded_file)
        file_content = df.to_string(index=False)
    elif file_name.endswith(".csv"):
        df = pd.read_csv(uploaded_file)
        file_content = df.to_string(index=False)
    else:
        file_bytes = uploaded_file.read()
        result = from_bytes(file_bytes).best()
        if result is None:
            raise ValueError("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö encoding ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ")
        file_content = str(result)

    # ‚úÖ ‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÑ‡∏°‡πà‡πÅ‡∏ö‡πà‡∏á chunk)
    docs = [Document(page_content=file_content)]
    return docs, file_content
# ===== üß† ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå‡∏î‡πâ‡∏ß‡∏¢ Prompt ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å =====
def process_uploaded_file_for_prompt(uploaded_file):
    """‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Prompt"""
    try:
        uploaded_file.seek(0)
        docs, file_content = get_split_docs(uploaded_file)

        st.session_state["split_docs"] = docs
        st.session_state["file_content"] = file_content
        st.session_state["analysis_results"] = []

        st.success("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
        st.text_area("üìÑ ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå", file_content, height=200, disabled=True)

    except Exception as e:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ: {e}")
        st.stop()   
## ============================== ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå ==============================

# üì• ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå AI (txt / md)
def show_download_section():
    if st.session_state.get("show_download"):
        st.markdown("### üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")

        file_format = st.selectbox(
            "üìÑ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå", 
            ["txt", "csv", "xlsx"],
            key="download_format"
        )

        file_name = st.text_input(
            "üìÅ ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå", 
            value="analysis_result", 
            key="download_filename"
        )

        full_filename = f"{file_name.strip()}.{file_format}"
        file_bytes = BytesIO()

        # ‚ñ∂Ô∏è ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á (csv, xlsx)
        if file_format in ["csv", "xlsx"] and st.session_state.get("analysis_result_table") is not None:
            raw_data = st.session_state["analysis_result_table"]

            # üß† ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame
            if isinstance(raw_data, list):
                if all(isinstance(item, list) for item in raw_data):
                    # ‚õ≥Ô∏è list of list ‚Üí ‡πÅ‡∏¢‡∏Å header ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                    if len(raw_data) >= 2:
                        header = raw_data[0]
                        rows = raw_data[1:]
                        df = pd.DataFrame(rows, columns=header)
                    else:
                        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á")
                        return
                elif all(isinstance(item, dict) for item in raw_data):
                    df = pd.DataFrame(raw_data)
                else:
                    st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô list of list ‡∏´‡∏£‡∏∑‡∏≠ list of dict)")
                    return
            else:
                st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÑ‡∏î‡πâ")
                return

            with st.expander("üîç ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á"):
                st.dataframe(df)

            if file_format == "csv":
                df.to_csv(file_bytes, index=False, encoding="utf-8-sig")
                mime_type = "text/csv"
            elif file_format == "xlsx":
                with pd.ExcelWriter(file_bytes, engine="xlsxwriter") as writer:
                    df.to_excel(writer, index=False, sheet_name="Result")
                mime_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"

        else:
            # ‚ñ∂Ô∏è ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ (txt)
            content = st.session_state.get("analysis_result", "")
            if not content.strip():
                st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
                return

            with st.expander("üîç ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å"):
                st.text(content)
            file_bytes.write(content.encode("utf-8"))
            mime_type = "text/plain"

        file_bytes.seek(0)

        # ‚¨áÔ∏è ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
        st.download_button(
            label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå",
            data=file_bytes,
            file_name=full_filename,
            mime=mime_type
        )