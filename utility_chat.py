# utility.py
import streamlit as st
import os
import sqlite3
import pandas as pd
from io import StringIO
from io import BytesIO
from openai import OpenAI
from datetime import datetime
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import TextLoader
from langchain.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
from charset_normalizer import from_bytes
from dotenv import load_dotenv
import tiktoken
import json
import time
import math
import requests
# ==== import libary ====

# ==== global path ====
db_folder = os.path.join("data")
db_path = os.path.join("data", "sqdata.db")
schema_path = os.path.join("data", "schema.sql")
user_id = st.session_state.get("user_id")
# ==== global path ====

# ‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å config.py ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ os.getenv() ‡πÄ‡∏≠‡∏á
from config import OPENAI_API_KEY,CHAT_TOKEN

# ===== OpenAI Client =====
client = OpenAI(api_key=OPENAI_API_KEY)

# ===== ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• SQLite =====
def init_db():
    if not os.path.exists(db_folder):
        os.makedirs(db_folder)

    first_time = not os.path.exists(db_path)
    conn = sqlite3.connect(db_path, check_same_thread=False)
    
    if first_time:
        initialize_schema(conn)
        
    return conn, conn.cursor()

# ===== ‡πÇ‡∏´‡∏•‡∏î schema.sql ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á =====
def initialize_schema(conn, schema_path=schema_path):
    """
    ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô SQL schema ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .sql ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏
    """
    if not os.path.exists(schema_path):
        raise FileNotFoundError(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå schema: {schema_path}")

    with open(schema_path, "r", encoding="utf-8") as f:
        sql_script = f.read().strip()

    if not sql_script:
        raise ValueError("‚ö†Ô∏è ‡πÑ‡∏ü‡∏•‡πå schema ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")

    try:
        conn.executescript(sql_script)
        conn.commit()
        print("‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á schema ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á schema: {e}")


# ===== ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• =====
def save_conversation_if_ready(
    conn,
    cursor,
    messages_key="messages_gpt",
    source="chat_gpt",
    title=None,
    **token_usage,
):
    import streamlit as st

    messages = st.session_state.get(messages_key, [])
    conv_key = f"conversation_id_{messages_key}"
    last_key = f"last_saved_count_{messages_key}"
    conv_id = st.session_state.get(conv_key)
    last_saved_count = st.session_state.get(last_key, 0)
    user_id = st.session_state.get("user_id", "guest")

    # ‚úÖ ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤ History
    if "conv_id" in st.session_state and conv_id is None:
        conv_id = st.session_state["conv_id"]
        st.session_state[conv_key] = conv_id

    # ‚úÖ ‡∏Å‡∏£‡∏ì‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
    if title and conv_id:
        try:
            cursor.execute(
                "UPDATE conversations SET title = ? WHERE id = ?",
                (title.strip(), conv_id),
            )
            conn.commit()
            st.toast("‚úèÔ∏è ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß", icon="‚úÖ")
        except Exception as e:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏î‡πâ: {e}")
        return conv_id

    # ‚úÖ ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡∏°‡πà‡∏Å‡∏ß‡πà‡∏≤‡∏£‡∏≠‡∏ö‡∏Å‡πà‡∏≠‡∏ô
    if len(messages) >= 2 and len(messages) > last_saved_count:
        last_two = messages[-2:]
        if last_two[0]["role"] == "user" and last_two[1]["role"] == "assistant":
            if conv_id is None:
                try:
                    from utility_ai import generate_title_from_conversation

                    title = title or generate_title_from_conversation(messages)
                except Exception:
                    title = title or messages[0].get("content", "‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà")[:30]

                cursor.execute(
                    """
                    INSERT INTO conversations (
                        user_id, title, source,
                        prompt_tokens, completion_tokens, total_tokens
                    ) VALUES (?, ?, ?, ?, ?, ?)
                    """,
                    (
                        user_id,
                        title,
                        source,
                        token_usage.get("prompt_tokens", 0),
                        token_usage.get("completion_tokens", 0),
                        token_usage.get("total_tokens", 0),
                    ),
                )
                conv_id = cursor.lastrowid
                st.session_state[conv_key] = conv_id

            try:
                # ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                for msg in messages[last_saved_count:]:
                    cursor.execute(
                        """
                        INSERT INTO messages (
                            user_id, conversation_id, role, content,
                            prompt_tokens, completion_tokens, total_tokens,
                            response_json
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                        """,
                        (
                            user_id,
                            conv_id,
                            msg.get("role", "user"),
                            msg.get("content", ""),
                            msg.get("prompt_tokens", 0),
                            msg.get("completion_tokens", 0),
                            msg.get("total_tokens", 0),
                            msg.get("response_json", "{}"),
                        ),
                    )

                    message_id = cursor.lastrowid
                    if msg.get("role") == "assistant":
                        cursor.execute(
                            """
                            INSERT INTO raw_json (conversation_id, message_id, response_json)
                            VALUES (?, ?, ?)
                            """,
                            (
                                conv_id,
                                message_id,
                                msg.get("response_json", "{}"),
                            ),
                        )

                # ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Token Usage
                log_token_usage(
                    conn,
                    cursor,
                    user_id,
                    source,
                    token_usage.get("prompt_tokens", 0),
                    token_usage.get("completion_tokens", 0),
                    token_usage.get("total_tokens", 0),
                )

                conn.commit()
                st.session_state[last_key] = len(messages)
                st.toast(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å {source}", icon="üí¨")

            except Exception as e:
                st.error(f"‚ùå ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")
                return None

    return conv_id

#
def log_token_usage(
    conn, cursor, user_id, model, prompt_tokens, completion_tokens, total_tokens
):
    try:
        cursor.execute(
            """
            INSERT INTO token_usage (user_id, model, prompt_tokens, completion_tokens, total_tokens, created_at)
            VALUES (?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
            """,
            (user_id, model, prompt_tokens, completion_tokens, total_tokens),
        )
        conn.commit()
    except Exception as e:
        import streamlit as st

        st.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å token usage ‡πÑ‡∏î‡πâ: {e}")

def get_token_usage_summary(cursor, user_id=None):
    query = """
        SELECT user_id, SUM(total_tokens) as total_tokens
        FROM token_usage
    """
    params = []

    if user_id:
        query += " WHERE user_id = ?"
        params.append(user_id)

    query += " GROUP BY user_id"

    cursor.execute(query, params)
    return cursor.fetchall()


# ===== ‡πÉ‡∏ä‡πâ AI ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏ö‡∏ö‡∏¢‡πà‡∏≠ =====
def generate_title_from_conversation(messages, model="gpt-4o"):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ GPT (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ 5-10 ‡∏Ñ‡∏≥)
    """
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

        system_prompt = {
            "role": "system",
            "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ç‡∏≠‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÇ‡∏î‡∏¢‡∏™‡∏£‡∏∏‡∏õ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ 5-10 ‡∏Ñ‡∏≥",
        }

        final_messages = (
            [system_prompt]
            + messages
            + [{"role": "user", "content": "‡∏™‡∏£‡∏∏‡∏õ‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ç‡∏≠‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ô‡∏µ‡πâ‡∏™‡∏±‡πâ‡∏ô ‡πÜ"}]
        )

        response = client.chat.completions.create(model=model, messages=final_messages)

        return response.choices[0].message.content.strip()

    except Exception as e:
        print("‚ö†Ô∏è generate_title_from_conversation Error:", e)
        return (
            "‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà"
            if not messages
            else messages[0].get("content", "‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà")[:30]
        )

def save_conversation_title(cursor, title):
    """
    ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ (conversation.title) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å save_conversation_if_ready() ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    """
    # ‡∏î‡∏∂‡∏á conversation_id ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    cursor.execute("SELECT MAX(id) FROM conversations")
    result = cursor.fetchone()
    if result and result[0]:
        conversation_id = result[0]
        cursor.execute(
            "UPDATE conversations SET title = ? WHERE id = ?", (title, conversation_id)
        )

# ===== ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ =====
def list_conversations(user_id=None):
    db_path = os.path.join("data", "sqdata.db")
    conn = sqlite3.connect(db_path, check_same_thread=False)

    # ‡πÄ‡∏û‡∏¥‡πà‡∏° token columns
    query = """
        SELECT id, user_id, title, source,
               prompt_tokens, completion_tokens, total_tokens,
               created_at
        FROM conversations
    """
    params = ()

    if user_id:
        query += " WHERE user_id = ?"
        params = (user_id,)

    query += " ORDER BY created_at DESC"
    df = pd.read_sql_query(query, conn, params=params)
    conn.close()
    return df.values.tolist()

# ===== ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏≤‡∏£‡∏≤‡∏á Prompt =====
def init_prompt_table():
    conn = sqlite3.connect(db_path, check_same_thread=False)
    cursor = conn.cursor()
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS prompts 
            prompt_name TEXT,
            user_id TEXT NOT NULL,
            content TEXT,
            prompt_tokens INTEGER,
            completion_tokens INTEGER,
            total_tokens INTEGER,
            PRIMARY KEY (prompt_name, user_id)
        )
    """)
    conn.commit()
def save_prompt(prompt_name, content):
    user_id = st.session_state.get("user_id")
    if not user_id:
        st.warning("‚õî ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö")
        return
    conn = sqlite3.connect(db_path, check_same_thread=False)
    cursor = conn.cursor()
    cursor.execute("""
        REPLACE INTO prompts (prompt_name, user_id, content, prompt_tokens, completion_tokens, total_tokens)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (prompt_name, user_id, content, 0, 0, 0))  # ‡∏õ‡∏£‡∏±‡∏ö token = 0 ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ö parameter ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
    conn.commit()
    conn.close()
def list_prompts():
    user_id = st.session_state.get("user_id")
    role = st.session_state.get("Role", "user")

    conn = sqlite3.connect(db_path, check_same_thread=False)
    cursor = conn.cursor()

    if role == "admin":
        cursor.execute("SELECT prompt_name, content FROM prompts ORDER BY prompt_name")
    else:
        cursor.execute("SELECT prompt_name, content FROM prompts WHERE user_id = ? ORDER BY prompt_name", (user_id,))
    results = cursor.fetchall()
    conn.close()
    return results
def delete_prompt(name):
    user_id = st.session_state.get("user_id")
    role = st.session_state.get("Role", "user")

    conn = sqlite3.connect(db_path, check_same_thread=False)
    cursor = conn.cursor()

    if role == "admin":
        cursor.execute("DELETE FROM prompts WHERE prompt_name = ?", (name,))
    else:
        cursor.execute("DELETE FROM prompts WHERE prompt_name = ? AND user_id = ?", (name, user_id))

    conn.commit()
    conn.close()

## ============================== ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå ==============================
# ===== ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö encoding ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° =====
def try_decode_file(file_bytes: bytes) -> str:
    try:
        result = from_bytes(file_bytes).best()
        if result:
            return str(result)
    except Exception:
        pass
    try:
        return file_bytes.decode("utf-8")
    except UnicodeDecodeError:
        return file_bytes.decode("iso-8859-1", errors="replace")
# ===== ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á RAG Chain =====
def process_file_to_chain(uploaded_file):
    if not uploaded_file:
        st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Å‡πà‡∏≠‡∏ô")
        return

    with st.spinner("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå..."):
        try:
            file_bytes = uploaded_file.read()
            file_content = try_decode_file(file_bytes)
            st.text_area("üìñ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤", file_content[:1000], height=200, disabled=True)

            doc = Document(page_content=file_content)
            splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=300)
            chunks = splitter.split_documents([doc])
            st.success(f"üìö ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô {len(chunks)} ‡∏™‡πà‡∏ß‡∏ô‡∏¢‡πà‡∏≠‡∏¢")

            embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
            vectorstore = Chroma.from_documents(chunks, embedding=embeddings)

            chain = ConversationalRetrievalChain.from_llm(
                llm=ChatOpenAI(model="model_name", temperature=0, openai_api_key=OPENAI_API_KEY),
                retriever=vectorstore.as_retriever(),
                memory=ConversationBufferMemory(memory_key="chat_history", return_messages=True),
            )

            st.session_state["chain"] = chain
            st.session_state["chat_history"] = []
            st.session_state["file_content"] = file_content
            st.success("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")

        except Exception as e:
            st.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
# ===== üîé ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î =====
def read_uploaded_file(file_name, uploaded_file, chunk_size=5000):
    file_name = file_name.lower()
    my_bar = st.progress(0, text="üì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå...")
    uploaded_file.seek(0)

    if file_name.endswith(".xlsx"):
        df = pd.read_excel(uploaded_file)
        content = df.to_string(index=False)
    elif file_name.endswith(".csv"):
        df = pd.read_csv(uploaded_file)
        content = df.to_string(index=False)
    else:
        file_bytes = uploaded_file.read()
        result = from_bytes(file_bytes).best()
        content = str(result) if result else file_bytes.decode("utf-8")

    total_parts = math.ceil(len(content) / chunk_size)
    collected = []

    for i in range(total_parts):
        part = content[i * chunk_size : (i + 1) * chunk_size]
        collected.append(part)
        percent = int((i + 1) / total_parts * 100)
        my_bar.progress(percent, text=f"üìÑ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà {i+1}/{total_parts} ({percent}%)")
        time.sleep(0.01)

    my_bar.empty()
    return "".join(collected)
# ===== üí¨ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏á‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó =====
def append_chat(role, content, state_key="chat_history"):
    """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏á‡πÉ‡∏ô session chat"""
    st.chat_message(role).write(content)
    st.session_state.setdefault(state_key, []).append({
        "role": role,
        "content": content
    })
# ===== ‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô Document ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM =====
def get_split_docs(uploaded_file, chunk_size=3000, chunk_overlap=200):
    """‡πÅ‡∏õ‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏≤‡∏¢ Document ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤"""
    file_name = uploaded_file.name.lower()

    # ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå
    if file_name.endswith(".xlsx"):
        df = pd.read_excel(uploaded_file)
        file_content = df.to_string(index=False)
    elif file_name.endswith(".csv"):
        df = pd.read_csv(uploaded_file)
        file_content = df.to_string(index=False)
    else:
        file_bytes = uploaded_file.read()
        result = from_bytes(file_bytes).best()
        if result is None:
            raise ValueError("‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö encoding ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ")
        file_content = str(result)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Document ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡πà‡∏≠‡∏ô
    doc = Document(page_content=file_content)

    # ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏≤‡∏¢ chunk
    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    all_chunks = splitter.split_documents([doc])
    total = len(all_chunks)

    # ‡πÅ‡∏™‡∏î‡∏á progress
    st.info(f"üìÑ ‡πÅ‡∏ö‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô {total} ‡∏™‡πà‡∏ß‡∏ô ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•...")

    progress_bar = st.progress(0)
    processed_chunks = []
    for i, chunk in enumerate(all_chunks):
        processed_chunks.append(chunk)

        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        percent_complete = int((i + 1) / total * 100)
        progress_bar.progress(percent_complete)
        time.sleep(0.01)  # ‡∏à‡∏≥‡∏•‡∏≠‡∏á delay (‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡∏à‡∏£‡∏¥‡∏á)

    st.success("‚úÖ ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô!")

    return processed_chunks, file_content
# ===== ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å GPT ‡πÅ‡∏•‡∏∞‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á (DataFrame) =====
def call_openai_with_parsing(full_input, system_prompt):
    from openai import OpenAI
    client = OpenAI(api_key=OPENAI_API_KEY)

    base_messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": full_input}
    ]

    response = client.chat.completions.create(
        model="model_name",
        messages=base_messages
    )

    reply = response.choices[0].message.content
    usage = response.usage
    raw_json = json.dumps(response.model_dump(), ensure_ascii=False)

    df_result = None
    try:
        if "|" in reply and "---" in reply:
            lines = [line for line in reply.splitlines() if "|" in line and not line.strip().startswith("---")]
            cleaned = "\n".join(lines)
            df_result = pd.read_csv(StringIO(cleaned), sep="|").dropna(axis=1, how="all")
        elif "," in reply:
            df_result = pd.read_csv(StringIO(reply))
    except Exception:
        df_result = None


    return reply, df_result, usage, raw_json
# ===== üß† ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå‡∏î‡πâ‡∏ß‡∏¢ Prompt ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å =====
def process_uploaded_files_for_prompt(uploaded_files):
    all_contents = []
    st.session_state["uploaded_filename"] = []
    st.session_state["analysis_results"] = []

    for uploaded_file in uploaded_files:
        try:
            uploaded_file.seek(0)
            file_name = uploaded_file.name.lower()
            st.session_state["uploaded_filename"].append(uploaded_file.name)

            if file_name.endswith(".txt"):
                content = uploaded_file.read().decode("utf-8", errors="ignore")
            elif file_name.endswith(".csv"):
                df = pd.read_csv(uploaded_file)
                content = df.to_csv(index=False)
            elif file_name.endswith(".xlsx"):
                df = pd.read_excel(uploaded_file)
                content = df.to_csv(index=False)
            else:
                st.warning(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö: {file_name}")
                continue

            # ‡∏£‡∏ß‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            all_contents.append(f"### ‡πÑ‡∏ü‡∏•‡πå: {uploaded_file.name}\n{content}")
            st.text_area(
                f"üìÑ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å {uploaded_file.name}",
                content[:3000],
                height=200,
                disabled=True,
            )

        except Exception as e:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå {uploaded_file.name} ‡πÑ‡∏î‡πâ: {e}")

    # ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô‡πÉ‡∏ô session
    st.session_state["file_content"] = "\n\n".join(all_contents)
    st.success("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

# üì• ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå AI (txt / md)
def show_download_section():
    if st.session_state.get("show_download"):
        st.markdown("### üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")

        file_format = st.selectbox(
            "üìÑ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå", ["txt", "csv", "xlsx"], key="download_format"
        )

        file_name = st.text_input(
            "üìÅ ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå", value="analysis_result", key="download_filename"
        )

        full_filename = f"{file_name.strip()}.{file_format}"
        file_bytes = BytesIO()

        # ‚ñ∂Ô∏è ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á (csv, xlsx)
        if (
            file_format in ["csv", "xlsx"]
            and st.session_state.get("analysis_result_table") is not None
        ):
            raw_data = st.session_state["analysis_result_table"]

            # üß† ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame
            if isinstance(raw_data, list):
                if all(isinstance(item, list) for item in raw_data):
                    # ‚õ≥Ô∏è list of list ‚Üí ‡πÅ‡∏¢‡∏Å header ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                    if len(raw_data) >= 2:
                        header = raw_data[0]
                        rows = raw_data[1:]
                        df = pd.DataFrame(rows, columns=header)
                    else:
                        st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á")
                        return
                elif all(isinstance(item, dict) for item in raw_data):
                    df = pd.DataFrame(raw_data)
                else:
                    st.warning(
                        "‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô list of list ‡∏´‡∏£‡∏∑‡∏≠ list of dict)"
                    )
                    return
            else:
                st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÑ‡∏î‡πâ")
                return

            with st.expander("üîç ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡∏ï‡∏≤‡∏£‡∏≤‡∏á"):
                st.dataframe(df)

            if file_format == "csv":
                df.to_csv(file_bytes, index=False, encoding="utf-8-sig")
                mime_type = "text/csv"
            elif file_format == "xlsx":
                with pd.ExcelWriter(file_bytes, engine="xlsxwriter") as writer:
                    df.to_excel(writer, index=False, sheet_name="Result")
                mime_type = (
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

        else:
            # ‚ñ∂Ô∏è ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ (txt)
            content = st.session_state.get("analysis_result", "")
            if not content.strip():
                st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
                return

            with st.expander("üîç ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å"):
                st.text(content)
            file_bytes.write(content.encode("utf-8"))
            mime_type = "text/plain"

        file_bytes.seek(0)

        # ‚¨áÔ∏è ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
        st.download_button(
            label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå",
            data=file_bytes,
            file_name=full_filename,
            mime=mime_type,
        )


## ============================== ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå ==============================

# Reset ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏´‡∏ô‡πâ‡∏≤
def reset_tab(tab_choice, model_choice):
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏ó‡πá‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•
    if "tab_last" not in st.session_state:
        st.session_state["tab_last"] = tab_choice
    if "model_last" not in st.session_state:
        st.session_state["model_last"] = model_choice

    if (
        st.session_state["tab_last"] != tab_choice
        or st.session_state["model_last"] != model_choice
    ):
        for key in [
            "messages_gpt",
            "chat_all_in_one",
            "conversation_id_messages_gpt",
            "conversation_id_chat_all_in_one",
            "last_saved_count_messages_gpt",
            "last_saved_count_chat_all_in_one",
            "analysis_result",
            "show_download",
            "file_text",
        ]:
            st.session_state.pop(key, None)

        st.session_state["tab_last"] = tab_choice
        st.session_state["model_last"] = model_choice
        st.rerun()

def reset_on_button_click():
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä
    if "last_button_pressed" not in st.session_state:
        st.session_state["last_button_pressed"] = None
    if (
        "button_pressed" in st.session_state
        and st.session_state["button_pressed"]
        != st.session_state["last_button_pressed"]
    ):
        st.session_state["last_button_pressed"] = st.session_state["button_pressed"]
        st.rerun()
