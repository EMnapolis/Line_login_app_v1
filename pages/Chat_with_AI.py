# page/chat_with_ai.py
from utility_chat import *  # ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå utility.py
from utility_ai import *

client = OpenAI(api_key=OPENAI_API_KEY)
# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ SQLite
conn, cursor = init_db()
initialize_schema(conn)

# ============================
# üåê GLOBAL PATHS & CONSTANTS
# ============================

# ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
TABLE_NAME_CHAT = "chat_gpt"
TABLE_NAME_PROMPT = "prompt_store"

# ‡∏Ñ‡∏µ‡∏¢‡πå‡πÉ‡∏ô session_state
KEY_MESSAGES = "messages_gpt"
KEY_ANALYSIS_RESULT = "analysis_result"
KEY_SHOW_DOWNLOAD = "show_download"
KEY_CHAT_HISTORY = "chat_all_in_one"
KEY_SELECTED_PROMPT = "prompt_selector"

# MIME types
MIME_TYPES = {
    "txt": "text/plain",
    "md": "text/markdown",
}
file_content = ""
# ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
DEFAULT_FILENAME = "analysis_result"

# System prompt ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
DEFAULT_SYSTEM_PROMPT = "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏≤‡∏Å‡∏°‡∏µ"

# ========== ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤ Streamlit ==========
CHAT_TOKEN_VL = os.getenv("CHAT_TOKEN") or "Empty"  # Set ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ chat_token_vl

# ========== Role + User ==========
role = st.session_state.get("Role", "")
current_user = st.session_state.get("user_id", "")
# ----------------------------
# ‚öôÔ∏è Debug Mode Configuration
# ----------------------------
DEBUG = os.getenv("DEBUG", "0") == "1"

if DEBUG:
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ session ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ mock ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    if "user_id" not in st.session_state:
        st.session_state["user_id"] = "Udebug123456"
        st.session_state["displayName"] = "U TEST"
        st.session_state["pictureUrl"] = "https://i.imgur.com/1Q9Z1Zm.png"
        st.session_state["status"] = "APPROVED"
        st.session_state["Role"] = "user"
        st.info("üîß Loaded mock user session for debugging.")

st.page_link("app.py", label="‚¨ÖÔ∏è ‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å", icon="üè†")
st.title("ü§ñ AI Chat Platform")
# ---------------
# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à login ‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå
if "user_id" not in st.session_state or st.session_state.get("status") != "APPROVED":
    st.error("üö´ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    st.stop()
# ---------------
with st.sidebar:
    st.markdown("### üìë ‡πÄ‡∏°‡∏ô‡∏π‡∏´‡∏•‡∏±‡∏Å")
    tab_choice = st.radio(
        "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏°‡∏ô‡∏π",
        ["üí¨ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö GPT", "üß† ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö Prompt", "üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", "üìò ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"],
    )
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # üõ† ‡∏õ‡∏∏‡πà‡∏°‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏ö (‡πÉ‡∏ô Sidebar)
    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    st.markdown("---")
    st.markdown("### üõ† ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤")

    # ‚úÖ ‡∏õ‡∏∏‡πà‡∏°‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á AI
    if st.button("‚õî ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô", key="stop_button_sidebar"):
        st.session_state["stop_chat"] = True
        st.warning("üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á AI ‡πÅ‡∏•‡πâ‡∏ß")

    # ‚úÖ ‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡∏°‡πà
    if st.button("üÜï ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà", key="reset_button_sidebar"):
        for key in [
            "chat_all_in_one",
            "messages_prompt",
            "analysis_result",
            "file_content",
            "conversation_title",
            "uploaded_filename",
            "tab_last",
            "model_last",
        ]:
            st.session_state.pop(key, None)
        st.rerun()
    # ======= ‡∏î‡∏π Token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ô =======
    st.markdown("---")
    with st.expander("üìä Token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì", expanded=False):
        from utility_chat import init_db

        conn, cursor = init_db()

        # üîÑ ‡∏î‡∏∂‡∏á‡∏£‡∏ß‡∏° token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ï‡πà‡∏≠ user
        cursor.execute(
            """
            SELECT user_id, SUM(total_tokens) as total
            FROM token_usage
            GROUP BY user_id
            """
        )
        rows = cursor.fetchall()
        df = pd.DataFrame(rows, columns=["user_id", "‡∏£‡∏ß‡∏° Token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ"])

        # üß† ‡∏£‡∏∞‡∏ö‡∏∏‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        current_user = st.session_state.get("user_id", "")

        # üîç ‡∏î‡∏∂‡∏á quota override ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å DB ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö user ‡∏ô‡∏µ‡πâ
        cursor.execute(
            """
            SELECT quota_override FROM token_usage
            WHERE user_id = ?
            AND quota_override IS NOT NULL
            ORDER BY id DESC LIMIT 1
            """,
            (current_user,),
        )
        quota_row = cursor.fetchone()
        current_quota = (
            quota_row[0] if quota_row else 1_000_000
        )  # fallback ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ quota_override

        # ‚úÖ ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á user ‡∏ô‡∏µ‡πâ
        df = df[df["user_id"] == current_user]

        if df.empty:
            # üßæ ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ record token usage ‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô
            df = pd.DataFrame(
                [
                    {
                        "user_id": current_user,
                        "‡∏£‡∏ß‡∏° Token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ": 0,
                    }
                ]
            )

        # ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
        df["‡πÇ‡∏Ñ‡∏ß‡∏ï‡∏≤ Token"] = current_quota
        df["Token ‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"] = df["‡πÇ‡∏Ñ‡∏ß‡∏ï‡∏≤ Token"] - df["‡∏£‡∏ß‡∏° Token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ"]
        df["% ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß"] = (df["‡∏£‡∏ß‡∏° Token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ"] / df["‡πÇ‡∏Ñ‡∏ß‡∏ï‡∏≤ Token"] * 100).round(2)

        # ‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡∏£‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
        for _, row in df.iterrows():
            st.markdown(
                f"""
                üë§ `User ID`: `{row["user_id"]}`  
                üî¢ **‡∏£‡∏ß‡∏° Token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ**: `{row["‡∏£‡∏ß‡∏° Token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ"]:,}`  
                üéØ **‡πÇ‡∏Ñ‡∏ß‡∏ï‡∏≤ Token**: `{row["‡πÇ‡∏Ñ‡∏ß‡∏ï‡∏≤ Token"]:,}`  
                ‚úÖ **Token ‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠**: `{row["Token ‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠"]:,}`  
                üìà ‡πÉ‡∏ä‡πâ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß: `{row["% ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß"]}%`  
                ---
                """
            )


# TODO ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô‡πÅ‡∏ä‡∏ó)
# ==== ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å Ollama ====
ollama_models = (
    get_ollama_models())  # ‡∏Ñ‡∏ß‡∏£ return ‡πÄ‡∏õ‡πá‡∏ô list ‡πÄ‡∏ä‡πà‡∏ô ["gemma3:12b", "DSV2:16b"]
gpt_models = ["gpt-4o"]
chat_all_in_one = gpt_models + ollama_models

# ==== ‡∏ï‡∏±‡πâ‡∏á default model ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å ====
if "default_model" not in st.session_state:
    # ‡∏ï‡∏±‡πâ‡∏á gpt-4o ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ Ollama ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏à‡∏≤‡∏Å Ollama
    st.session_state["default_model"] = ollama_models[0] if ollama_models else "gpt-4o"

# ==== ‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö‡∏ã‡πà‡∏≠‡∏ô UI ====
with st.expander("‚öôÔ∏è ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏∞‡∏ö‡∏ö)"):
    try:
        default_model = st.selectbox(
            "üß† ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á",
            chat_all_in_one,
            index=chat_all_in_one.index(st.session_state["default_model"]),
            key="default_model_selector",
        )
    except ValueError:
        default_model = "gpt-4o"

    st.session_state["default_model"] = default_model

# ===== ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á =====
model_choice = st.session_state["default_model"]

st.markdown(f"‚úÖ **‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ:** `{model_choice}`", unsafe_allow_html=True)

# ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏ó‡πá‡∏ö
reset_tab(tab_choice, model_choice)
reset_on_button_click()
# ---------------
# ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô token ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
cursor.execute(
    """
    SELECT SUM(total_tokens) FROM token_usage WHERE user_id = ?
""",
    (current_user,),
)
row = cursor.fetchone()
used_token = row[0] or 0  # ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏•‡∏¢ row[0] ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô None

check_token_quota()
# ========== TAB 1: Chat with GPT ==========
if tab_choice == "üí¨ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö GPT":
    st.subheader("ü§ñ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö GPT (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö)")
    st.caption("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")

    with st.expander("üìÇ ‡∏Ç‡∏¢‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (txt, csv, xlsx)", expanded=False):
        uploaded_file = st.file_uploader("üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (txt, csv, xlsx)", 
                                         type=["txt", "csv", "xlsx"],
                                         accept_multiple_files=True)

    if uploaded_file:
        all_content = ""
        for uploaded_file in uploaded_file:
            try:
                file_content = read_uploaded_file(uploaded_file.name, uploaded_file)
                all_content += f"\n\n### {uploaded_file.name}\n{file_content}"

                st.text_area(
                    f"üìÑ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å {uploaded_file.name}",
                    file_content[:1000],
                    height=200,
                    disabled=True,
                )
                st.session_state[f"file_{uploaded_file.name}"] = file_content

            except Exception as e:
                st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {uploaded_file.name} ‡πÑ‡∏î‡πâ: {e}")

        # ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏ß‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö AI
        st.session_state["file_text"] = all_content

    # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    file_content = st.session_state.get("file_text", "")
    st.session_state.setdefault("chat_all_in_one", [])

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á
    for msg in st.session_state["chat_all_in_one"]:
        st.chat_message(msg["role"]).write(msg["content"])

    # ‡∏ä‡πà‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ß‡πà‡∏≤ '‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå')"):
        token_fn = count_tokens if model_choice.startswith("gpt-") else estimate_tokens

        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏° token_count
        st.chat_message("user").write(prompt)
        st.session_state["chat_all_in_one"].append(
            {
                "role": "user",
                "content": prompt,
                # "token_count": token_fn(prompt, model_choice),
            }
        )

        # ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå
        if prompt.strip() == "‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå":
            if not st.session_state.get("analysis_result"):
                st.chat_message("assistant").write("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡πâ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô")
            else:
                st.chat_message("assistant").write("üì¶ ‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å AI")
                st.session_state["show_download"] = True

        else:
            try:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡πÄ‡∏ï‡πá‡∏°
                base_messages = [
                    {
                        "role": "system",
                        "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏≤‡∏Å‡∏°‡∏µ",
                    }
                ]
                if file_content:
                    base_messages.append(
                        {"role": "user", "content": f"‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:\n{file_content}"}
                    )
                base_messages.extend(st.session_state["chat_all_in_one"])

                with st.chat_message("assistant"):
                    stream_output = st.empty()
                    result = display_ai_response_info(
                        model_choice, base_messages, stream_output
                    )

                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ history
                st.session_state["chat_all_in_one"].append(
                    {
                        "role": "assistant",
                        "content": result["reply"],
                        "prompt_tokens": result["prompt_tokens"],
                        "completion_tokens": result["completion_tokens"],
                        "total_tokens": result["total_tokens"],
                        "response_json": result["response_json"],
                    }
                )

                # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• / ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
                st.session_state["analysis_result"] = result["reply"]
                st.session_state["show_download"] = False

                # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö save DB
                st.session_state["messages_gpt"] = base_messages + [
                    {
                        "role": "assistant",
                        "content": result["reply"],
                        "prompt_tokens": result["prompt_tokens"],
                        "completion_tokens": result["completion_tokens"],
                        "total_tokens": result["total_tokens"],
                        "response_json": result["response_json"],
                    }
                ]

                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á SQLite
                save_conversation_if_ready(
                    conn,
                    cursor,
                    messages_key="messages_gpt",         # ‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
                    source=model_choice,                 # ‡πÄ‡∏ä‡πà‡∏ô "gpt-4o" ‡∏´‡∏£‡∏∑‡∏≠ "llama2:latest"
                    prompt_tokens=result["prompt_tokens"],
                    completion_tokens=result["completion_tokens"],
                    total_tokens=result["total_tokens"],
                )

                if "conversation_title" not in st.session_state:
                    from utility_ai import generate_title_from_conversation

                    title = generate_title_from_conversation(
                        st.session_state["messages_gpt"]
                    )
                    st.session_state["conversation_title"] = title  # ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô UI
                    save_conversation_if_ready(
                        cursor, title
                    )  # ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ DB
                    conn.commit()

            except Exception as e:
                st.error(f"‚ùå Error: {e}")

    # ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    show_download_section()

# ========== Choice 2: ‡πÄ‡∏û‡∏¥‡πà‡∏°/‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Prompt ==========
elif tab_choice == "üß† ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö Prompt":
    st.subheader("üß† ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö Prompt")

    tab_chat, tab_manage = st.tabs(["üí¨ Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ä‡∏ó‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ", "‚úçÔ∏è ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å / ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Prompt"])

    with tab_chat:
        st.caption("‡πÉ‡∏ä‡πâ Prompt ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö GPT ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡∏±‡∏Å‡∏ö‡∏±‡∏ç‡∏ä‡∏µ ‡∏ô‡∏±‡∏Å‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢")

        prompts = list_prompts()
        prompt_dict = {name: content for name, content in prompts}

        if prompt_dict:
            selected_prompt_name = st.selectbox(
                "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Prompt", list(prompt_dict.keys()), key="prompt_selector"
            )
            selected_prompt = prompt_dict[selected_prompt_name]

            with st.expander("‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° Prompt ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"):
                st.code(selected_prompt)

            st.session_state.setdefault("chat_all_in_one", [])
            st.session_state.setdefault("messages_prompt", [])
            st.session_state.setdefault("messages_gpt", [])

            for msg in st.session_state["chat_all_in_one"]:
                st.chat_message(msg["role"]).write(msg["content"])

            with st.expander("üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö)", expanded=False):
                uploaded_files = st.file_uploader(
                    "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (.txt, .csv, .xlsx) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Prompt (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)",
                    type=["txt", "csv", "xlsx"],
                    accept_multiple_files=True,
                )

            file_content_all = ""
            if uploaded_files:
                st.session_state["uploaded_filename"] = [f.name for f in uploaded_files]
                st.session_state["analysis_results"] = []
                for uploaded_file in uploaded_files:
                    try:
                        content = read_uploaded_file(uploaded_file.name, uploaded_file)
                        file_content_all += (
                            f"\n\n### ‡πÑ‡∏ü‡∏•‡πå: {uploaded_file.name}\n{content}"
                        )
                        st.text_area(
                            f"üìÑ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å {uploaded_file.name}",
                            content[:3000],
                            height=200,
                            disabled=True,
                        )
                        st.session_state[f"file_{uploaded_file.name}"] = content
                    except Exception as e:
                        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå {uploaded_file.name} ‡πÑ‡∏î‡πâ: {e}")

                st.session_state["file_content"] = file_content_all

                if st.button("üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå‡∏î‡πâ‡∏ß‡∏¢ Prompt ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"):
                    file_content = st.session_state.get("file_content", "")
                    prompt_input = f"‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:{selected_prompt} ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå:{file_content}"

                    base_messages = [
                        {"role": "system", "content": selected_prompt},
                        {"role": "user", "content": prompt_input},
                    ]

                    with st.chat_message("assistant"):
                        stream_output = st.empty()
                        result = display_ai_response_info(
                            model_choice, base_messages, stream_output
                        )

                    reply = result["reply"]
                    raw_json = result["response_json"]

                    st.session_state["chat_all_in_one"].append(
                        {"role": "assistant", "content": reply}
                    )
                    st.session_state["analysis_result"] = reply
                    st.session_state["show_download"] = False

                    st.session_state["messages_prompt"] = base_messages + [
                        {
                            "role": "assistant",
                            "content": reply,
                            "prompt_tokens": result["prompt_tokens"],
                            "completion_tokens": result["completion_tokens"],
                            "total_tokens": result["total_tokens"],
                            "response_json": raw_json,
                        }
                    ]

                    save_conversation_if_ready(
                        conn,
                        cursor,
                        messages_key="messages_prompt",
                        source=model_choice,
                        prompt_tokens=result["prompt_tokens"],
                        completion_tokens=result["completion_tokens"],
                        total_tokens=result["total_tokens"],
                    )

            # ‚úÖ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏ä‡∏ó‡∏ï‡πà‡∏≠
            if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ß‡πà‡∏≤ '‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå')"):
                st.chat_message("user").write(prompt)
                st.session_state["chat_all_in_one"].append(
                    {"role": "user", "content": prompt}
                )

                file_content = st.session_state.get("file_content", "")
                prompt_input = f"‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:{selected_prompt} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:{prompt}"

                base_messages = [
                    {"role": "system", "content": selected_prompt},
                    {"role": "user", "content": prompt_input},
                ]

                with st.chat_message("assistant"):
                    stream_output = st.empty()
                    result = display_ai_response_info(
                        model_choice, base_messages, stream_output
                    )

                reply = result["reply"]
                raw_json = result["response_json"]

                st.session_state["chat_all_in_one"].append(
                    {"role": "assistant", "content": reply}
                )
                st.session_state["analysis_result"] = reply
                st.session_state["show_download"] = False

                st.session_state["messages_prompt"] = base_messages + [
                    {
                        "role": "assistant",
                        "content": reply,
                        "prompt_tokens": result["prompt_tokens"],
                        "completion_tokens": result["completion_tokens"],
                        "total_tokens": result["total_tokens"],
                        "response_json": raw_json,
                    }
                ]

                save_conversation_if_ready(
                    conn,
                    cursor,
                    messages_key="messages_prompt",
                    source=model_choice,
                    prompt_tokens=result["prompt_tokens"],
                    completion_tokens=result["completion_tokens"],
                    total_tokens=result["total_tokens"],
                )

                show_download_section()

        else:
            st.warning("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ Prompt ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πá‡∏ö '‚ú® ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å / ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Prompt'")

    # ===== TAB 2: ‚úçÔ∏è ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å / ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Prompt =====
    with tab_manage:
        st.caption("‚úçÔ∏è ‡πÄ‡∏û‡∏¥‡πà‡∏° ‡∏•‡∏ö ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Prompt ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")

        # ===== ‡πÄ‡∏û‡∏¥‡πà‡∏° Prompt ‡πÉ‡∏´‡∏°‡πà =====
        prompt_name = st.text_input(
            "üìù ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠ Prompt ‡πÉ‡∏´‡∏°‡πà", key="prompt_name_input_create"
        )
        content = st.text_area(
            "üìÑ ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ Prompt", height=120, key="content_input_create"
        )
        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Prompt", key="save_prompt_create"):
            if prompt_name and content:
                save_prompt(prompt_name, content)
                st.success(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Prompt ‚Äú{prompt_name}‚Äù ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                st.toast("‚úÖ ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô", icon="‚úÖ")
                st.rerun()
            else:
                st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ Prompt")

        # ===== ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Prompt ‡∏ó‡∏µ‡πà‡∏°‡∏µ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç/‡∏•‡∏ö =====
        prompts = list_prompts()
        if prompts:
            st.markdown("### üóÇ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Prompt ‡∏ó‡∏µ‡πà‡∏°‡∏µ")
            for name, content in prompts:
                with st.expander(f"üìå {name}", expanded=False):
                    edited_content = st.text_area(
                        "üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ Prompt",
                        value=content,
                        height=150,
                        key=f"edit_{name}",
                    )

                    col1, col2 = st.columns([1, 1])
                    with col1:
                        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", key=f"save_edit_{name}"):
                            save_prompt(name, edited_content)
                            st.success(f"‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Prompt ‚Äú{name}‚Äù ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                            st.rerun()  # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏ô‡∏µ‡πâ‡πÅ‡∏ó‡∏ô experimental_rerun()

                    with col2:
                        if st.button("üóëÔ∏è ‡∏•‡∏ö Prompt ‡∏ô‡∏µ‡πâ", key=f"delete_prompt_{name}"):
                            delete_prompt(name)
                            st.success(f"‚úÖ ‡∏•‡∏ö‡πÅ‡∏•‡πâ‡∏ß: {name}")
                            st.rerun()  # ‚úÖ ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô
        else:
            st.info("‚ÑπÔ∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ Prompt ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")

# ========== Choice 3: History ==========
elif tab_choice == "üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤":
    st.subheader("üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤")
    # =========== ‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏£‡∏≠‡∏Å user id   ===========
    user_id = st.session_state.get("user_id")
    role = st.session_state.get("Role", "").lower()

    if role in ["admin", "super admin"]:
        convs_all = list_conversations()
    else:
        convs_all = list_conversations(user_id)

    # ===== ‡πÄ‡∏û‡∏¥‡πà‡∏° filter ‡∏ï‡∏≤‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏• =====
    st.sidebar.markdown("### üéõÔ∏è ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    model_filter = st.sidebar.selectbox(
        "üì¶ ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•", ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(list(set(c[3] for c in convs_all)))
    )

    if model_filter != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        convs = [c for c in convs_all if c[3] == model_filter]
    else:
        convs = convs_all

    if "messages_history" not in st.session_state:
        st.session_state["messages_history"] = []

    label_map = {
        f"{name} [{source}] ({created_at})": conv_id
        for conv_id, user_id, name, source, prompt_tokens, completion_tokens, total_tokens, created_at in convs
    }
    selected = st.selectbox("üìÅ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", ["- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å -"] + list(label_map.keys()))

    if selected != "- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å -":
        conv_id = label_map[selected]

        # ===== ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ä‡∏∑‡πà‡∏≠ =====
        title = selected.split(" [")[0]
        st.markdown(f"### üóÇÔ∏è ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: `{title}`")

        new_title = st.text_input(
            "‚úèÔ∏è ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", value=title, key="rename_title_input"
        )
        if new_title.strip() != title:
            cursor.execute(
                "UPDATE conversations SET title = ? WHERE id = ?",
                (new_title.strip(), conv_id),
            )
            conn.commit()
            st.success("‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
            st.rerun()

        cursor.execute(
            """
            SELECT role, content, prompt_tokens, completion_tokens, total_tokens
            FROM messages
            WHERE conversation_id = ?
            ORDER BY id
            """,
            (conv_id,),
        )
        rows = cursor.fetchall()
        messages = [
            {
                "role": r,
                "content": c,
                "prompt_tokens": p,
                "completion_tokens": comp,
                "total_tokens": total,
            }
            for r, c, p, comp, total in rows
        ]

        if (
            not st.session_state.get("messages_history")
            or st.session_state.get("conv_id") != conv_id
        ):
            st.session_state["messages_history"] = messages
            st.session_state["conv_id"] = conv_id

        MAX_CHARS = 300
        PREVIEW_CHARS = 50  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πá‡∏ô preview

        for msg in st.session_state.get("messages_history", []):
            role = msg.get("role", "user")
            content = msg.get("content", "").strip()

            with st.chat_message(role):
                if len(content) > MAX_CHARS:
                    preview = content[:PREVIEW_CHARS].rsplit(" ", 1)[0] + "..."  # ‡∏ï‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏à‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥
                    st.markdown(preview)  # ‡πÅ‡∏™‡∏î‡∏á preview ‡∏î‡πâ‡∏≤‡∏ô‡∏ô‡∏≠‡∏Å

                    with st.expander("üìÑ ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"):
                        st.markdown(content)
                else:
                    st.markdown(content)

                if role == "assistant" and msg.get("total_tokens"):
                    st.caption(
                        f"üî¢ Tokens: total={msg.get('total_tokens', 0)}, "
                        f"prompt={msg.get('prompt_tokens', 0)}, "
                        f"completion={msg.get('completion_tokens', 0)}"
                    )
        if prompt := st.chat_input(
            "üí¨ ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", key="chat_continue_input"
        ):
            st.chat_message("user").write(prompt)
            st.session_state["messages_history"].append(
                {"role": "user", "content": prompt}
            )

            try:
                with st.chat_message("assistant"):
                    stream_output = st.empty()
                    result = stream_response_by_model(
                        model_choice,
                        st.session_state["messages_history"],
                        stream_output,
                    )
                    reply = result["reply"]
                    stream_output.markdown(reply)

                st.session_state["messages_history"].append(
                    {
                        "role": "assistant",
                        "content": reply,
                        "prompt_tokens": result["prompt_tokens"],
                        "completion_tokens": result["completion_tokens"],
                        "total_tokens": result["total_tokens"],
                        "response_json": result["response_json"],
                    }
                )

                save_conversation_if_ready(
                    conn,
                    cursor,
                    messages_key="messages_history",
                    source=model_choice,
                    prompt_tokens=result["prompt_tokens"],
                    completion_tokens=result["completion_tokens"],
                    total_tokens=result["total_tokens"],
                )

            except Exception as e:
                st.error(f"‚ùå Error: {e}")

        with st.expander("üóëÔ∏è ‡∏•‡∏ö‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ô‡∏µ‡πâ"):
            if st.button("‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö", key="confirm_delete_conv"):
                cursor.execute(
                    "DELETE FROM messages WHERE conversation_id = ?", (conv_id,)
                )
                cursor.execute("DELETE FROM conversations WHERE id = ?", (conv_id,))
                conn.commit()

                reset_on_button_click()
                st.success("‚úÖ ‡∏•‡∏ö‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                st.rerun()

        if st.session_state.get("messages_history"):
            with st.expander("üìÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå"):
                file_format = st.selectbox(
                    "üìÑ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå",
                    ["txt", "md", "json", "csv"],
                    key="history_download_format",
                )
                file_name = st.text_input(
                    "üìù ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå", value="chat_history", key="history_download_filename"
                )

                full_filename = f"{file_name.strip()}.{file_format}"
                mime_type = "text/plain"
                content_lines = []
                file_bytes = StringIO()
                history = st.session_state["messages_history"]

                if file_format in ["txt", "md"]:
                    for msg in history:
                        role = msg.get("role", "unknown").capitalize()
                        text = msg.get("content", "").strip()
                        if not text:
                            continue
                        content_lines.append(
                            f"**{role}:**\n{text}\n"
                            if file_format == "md"
                            else f"{role}:\n{text}\n"
                        )
                        mime_type = (
                            "text/markdown" if file_format == "md" else "text/plain"
                        )
                    file_bytes.write("\n".join(content_lines))

                elif file_format == "json":
                    file_bytes.write(json.dumps(history, ensure_ascii=False, indent=2))
                    mime_type = "application/json"

                elif file_format == "csv":
                    pd.DataFrame(history).to_csv(
                        file_bytes, index=False, encoding="utf-8-sig"
                    )
                    mime_type = "text/csv"

                file_bytes.seek(0)
                st.download_button(
                    label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå",
                    data=file_bytes.getvalue(),
                    file_name=full_filename,
                    mime=mime_type,
                )

# ========== Choice 4 : ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ==========
if tab_choice == "üìò ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô":
    st.subheader("üìò ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
    tab_intro, tab_howto, tab_tip = st.tabs(
        ["üß© ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°", "üí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Chatai", "üí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"]
    )

    with tab_intro:
        st.subheader("üß© ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
        st.markdown(
            """
        ‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö AI ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Prompt ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏î‡πâ

        ### üß± ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
        ```plaintext
        ai_chat_platform/
        ‚îú‚îÄ‚îÄ app.py                 # üéØ ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å
        ‚îú‚îÄ‚îÄ utility.py             # üß† ‡∏£‡∏ß‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
        ‚îú‚îÄ‚îÄ .env                   # üîê ‡πÄ‡∏Å‡πá‡∏ö API Key ‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
        ‚îú‚îÄ‚îÄ /pages/
        ‚îÇ   ‚îú‚îÄ‚îÄ Chat_with_AI.py    # üí¨ ‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ä‡∏ó‡∏´‡∏•‡∏±‡∏Å
        ‚îÇ   ‚îú‚îÄ‚îÄ History.py         # üìú ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
        ‚îÇ   ‚îú‚îÄ‚îÄ Prompt_add.py      # üß† ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Prompt
        ‚îú‚îÄ‚îÄ /data/
        ‚îÇ   ‚îú‚îÄ‚îÄ sqdata.db          # üóÇ ‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• SQLite
        ‚îÇ   ‚îî‚îÄ‚îÄ schema.sql         # üìÑ ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        
        üõ† ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö
        ‚úÖ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö GPT-3.5/4 ‡πÑ‡∏î‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        ‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå .txt, .md, .csv ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
        ‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞
        ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å ‡πÅ‡∏•‡∏∞‡πÅ‡∏ä‡∏ó‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ
        ‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö LIFF ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏∑‡πà‡∏ô‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï
        """
        )

    with tab_howto:
        st.subheader("üìù ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏°‡∏ô‡∏π")
        st.markdown(
            """
        Chatai ‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏ú‡πà‡∏≤‡∏ô 4 ‡πÄ‡∏°‡∏ô‡∏π‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ ‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö GPT-3.5/4 ‡πÅ‡∏•‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ

        ### 1Ô∏è‚É£  üí¨ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö GPT
        - ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (üìÑ ‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå)
        - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏õ‡∏∏‡πà‡∏° **"üÜï ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏ä‡∏ó‡πÉ‡∏´‡∏°‡πà"**
        - ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏≠‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å GPT
        - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏õ‡∏∏‡πà‡∏° **"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"**
        ---
        ### 2Ô∏è‚É£ ‡πÉ‡∏ä‡πâ Prompt ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á (üß† ‡πÄ‡∏û‡∏¥‡πà‡∏°/‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Prompt)
        - ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡∏≠‡∏á GPT (‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡∏±‡∏Å‡∏ö‡∏±‡∏ç‡∏ä‡∏µ, ‡∏ô‡∏±‡∏Å‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢, ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤ ‡∏Ø‡∏•‡∏Ø)
        - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Prompt ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        - ‡πÅ‡∏ô‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ GPT ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Prompt ‡∏Å‡πá‡πÑ‡∏î‡πâ
        - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Prompt ‡πÑ‡∏î‡πâ‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á
        ---
        ###3Ô∏è‚É£ ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ (üìú ‡πÅ‡∏ä‡∏ó‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏¥‡∏°)
        - ‡∏î‡∏π‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ
        - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ > ‡πÅ‡∏ä‡∏ó‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
        - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï/‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ
        - **‡∏°‡∏µ‡∏õ‡∏∏‡πà‡∏°‡∏•‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
        ---
        üí° **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** ‡∏ó‡∏∏‡∏Å‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ü‡∏£‡∏µ‡∏ú‡πà‡∏≤‡∏ô GPT-3.5 ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô GPT-4 (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ API Key ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
        """
        )
        with tab_tip:
            st.markdown(
                """
        ## üí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        ---
        ### üß† ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡πÅ‡∏ö‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á
        ‡πÄ‡∏ä‡πà‡∏ô:
        - ‚Äú‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏ö‡∏±‡∏ç‡∏ä‡∏µ ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‚Äù
        - ‚Äú‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ó‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‚Äù
        ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
        ---
        ### üìÇ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
        - ‡πÉ‡∏ä‡πâ `.txt` ‡∏´‡∏£‡∏∑‡∏≠ `.csv` ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‚Üí ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
        - ‡πÉ‡∏ä‡πâ `.xlsx` ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÅ‡∏ö‡∏ö Excel
        ---
        ### üÜï ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏ä‡∏ó‡πÉ‡∏´‡∏°‡πà
        - ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó, ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î, ‡∏ú‡∏•‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
        - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÉ‡∏´‡∏°‡πà, ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà
        - ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå st.session_state ‡πÅ‡∏•‡∏∞ rerun
        ---
        ###üîÑ ‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏´‡∏ô‡πâ‡∏≤
        - ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà ‡πÇ‡∏î‡∏¢ ‡πÑ‡∏°‡πà‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°
        - ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï UI ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        - ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å st.experimental_rerun() ‡πÄ‡∏â‡∏¢ ‡πÜ
        ---
        ### üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
        - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô‡∏ü‡∏≠‡∏£‡πå‡πÅ‡∏°‡∏ï‡∏ï‡πà‡∏≤‡∏á ‡πÜ:
        - `.txt` ‚Üí ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        - `.md` ‚Üí ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Markdown
        - `.csv` ‚Üí ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏£‡∏≤‡∏á
        - `.xlsx` ‚Üí ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ô Excel
        ---
        ### üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏î‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥!
        - ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡πÄ‡∏°‡∏ô‡∏π **üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤**
        - ‡πÅ‡∏ä‡∏ó‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏î‡∏¥‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏î‡πâ
        ---
        """
            )

# Footer ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏î
st.markdown(
    """
    <hr style='margin-top: 3rem;'>
    <div style='text-align: center; color: gray;'>
        Provide ‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ‡∏ß‡∏¥‡∏•‡∏•‡πà‡∏≤ ‡∏°‡∏≤‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ï‡πÄ‡∏à‡∏û‡∏µ ‡πÇ‡∏î‡∏¢‡∏¢‡∏π‡∏ô‡∏¥‡∏Ñ‡∏≠‡∏£‡πå‡∏ô ‡πÄ‡∏ó‡∏Ñ ‡∏≠‡∏¥‡∏ô‡∏ó‡∏£‡∏¥‡πÄ‡∏Å‡∏£‡∏ä‡∏±‡πà‡∏ô
    </div>
""",
    unsafe_allow_html=True,
)
