# page/chat_with_ai.py
from utility_chat import *  # ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå utility.py
from utility_ai import *
client = OpenAI(api_key=OPENAI_API_KEY)
# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ SQLite
conn, cursor = init_db()
initialize_schema(conn)

# ============================
# üåê GLOBAL PATHS & CONSTANTS
# ============================

# ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
TABLE_NAME_CHAT = "chat_gpt"
TABLE_NAME_PROMPT = "prompt_store"

# ‡∏Ñ‡∏µ‡∏¢‡πå‡πÉ‡∏ô session_state
KEY_MESSAGES = "messages_gpt"
KEY_ANALYSIS_RESULT = "analysis_result"
KEY_SHOW_DOWNLOAD = "show_download"
KEY_CHAT_HISTORY = "chat_all_in_one"
KEY_SELECTED_PROMPT = "prompt_selector"

# MIME types
MIME_TYPES = {
	"txt": "text/plain",
	"md": "text/markdown",
}
file_content = ""
# ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
DEFAULT_FILENAME = "analysis_result"

# System prompt ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
DEFAULT_SYSTEM_PROMPT = "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏≤‡∏Å‡∏°‡∏µ"

# ========== ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏´‡∏ô‡πâ‡∏≤ Streamlit ==========
CHAT_TOKEN_VL = os.getenv("CHAT_TOKEN") or "Empty"  # Set ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ chat_token_vl

# ========== Role ==========
role = st.session_state.get("Role", "")

# ----------------------------
# ‚öôÔ∏è Debug Mode Configuration
# ----------------------------
DEBUG = os.getenv("DEBUG", "0") == "1"

if DEBUG:
	# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ session ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ mock ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö
	if "user_id" not in st.session_state:
		st.session_state["user_id"] = "Udebug123456"
		st.session_state["displayName"] = "U TEST"
		st.session_state["pictureUrl"] = "https://i.imgur.com/1Q9Z1Zm.png"
		st.session_state["status"] = "APPROVED"
		st.session_state["Role"] = "user"
		st.info("üîß Loaded mock user session for debugging.")

st.page_link("app.py", label="‚¨ÖÔ∏è ‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å", icon="üè†")
st.title("ü§ñ AI Chat Platform")
# ---------------
# ‚úÖ ‡∏ï‡∏£‡∏ß‡∏à login ‡πÅ‡∏•‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå
if "user_id" not in st.session_state or st.session_state.get("status") != "APPROVED":
	st.error("üö´ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
	st.stop()
# ---------------
with st.sidebar:
	st.markdown("### üìë ‡πÄ‡∏°‡∏ô‡∏π‡∏´‡∏•‡∏±‡∏Å")
	tab_choice = st.radio(
		"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏°‡∏ô‡∏π",
		["üí¨ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö GPT", "üß† ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö Prompt", "üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", "üìò ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô"],
	)
# TODO ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô‡πÅ‡∏ä‡∏ó)
if tab_choice == "üí¨ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö GPT":
	model_choice = st.radio(
		"üß† ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ",
		["gpt-4o", "gemma3:latest"],
		key="model_selector",
		horizontal=True,
	)
else:
	model_choice = None  # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏≠‡∏∑‡πà‡∏ô
# ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏ó‡πá‡∏ö
reset_tab(tab_choice, model_choice)
reset_on_button_click()

# ---------------
# ========== TAB 1: Chat with GPT ==========
if tab_choice == "üí¨ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö GPT":
    st.subheader("ü§ñ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö GPT (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö)")
    st.caption("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå")


    with st.expander("üìÇ ‡∏Ç‡∏¢‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (txt, csv, xlsx)", expanded=False):
        uploaded_file = st.file_uploader("üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (txt, csv, xlsx)", type=["txt", "csv", "xlsx"])

    if uploaded_file:
        try:
            file_content = read_uploaded_file(uploaded_file.name, uploaded_file)
            st.session_state["file_text"] = file_content
            st.text_area(
				"üìÑ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå", file_content[:1000], height=200, disabled=True
			)
        except Exception as e:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ: {e}")
            st.stop()

    # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    file_content = st.session_state.get("file_text", "")
    st.session_state.setdefault("chat_all_in_one", [])

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á
    for msg in st.session_state["chat_all_in_one"]:
        st.chat_message(msg["role"]).write(msg["content"])

    # ‡∏ä‡πà‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ß‡πà‡∏≤ '‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå')"):
        token_fn = count_tokens if model_choice.startswith("gpt-") else estimate_tokens

        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏° token_count
        st.chat_message("user").write(prompt)
        st.session_state["chat_all_in_one"].append(
			{
				"role": "user",
				"content": prompt,
				"token_count": token_fn(prompt, model_choice),
			}
		)

        # ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå
        if prompt.strip() == "‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå":
            if not st.session_state.get("analysis_result"):
                st.chat_message("assistant").write("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡πâ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô")
            else:
                st.chat_message("assistant").write("üì¶ ‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å AI")
                st.session_state["show_download"] = True

        else:
            try:
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á prompt ‡πÄ‡∏ï‡πá‡∏°
                base_messages = [
					{
						"role": "system",
						"content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏≤‡∏Å‡∏°‡∏µ",
					}
				]
                if file_content:
                    base_messages.append(
						{"role": "user", "content": f"‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:\n{file_content}"}
					)
                base_messages.extend(st.session_state["chat_all_in_one"])

                with st.chat_message("assistant"):
                    stream_output = st.empty()
                    result = stream_response_by_model(
						model_choice, base_messages, stream_output
					)
                    stream_output.markdown(result["reply"])

                # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ history
                st.session_state["chat_all_in_one"].append(
					{
						"role": "assistant",
						"content": result["reply"],
						"prompt_tokens": result["prompt_tokens"],
						"completion_tokens": result["completion_tokens"],
						"total_tokens": result["total_tokens"],
						"response_json": result["response_json"],
					}
				)

                # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• / ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
                st.session_state["analysis_result"] = result["reply"]
                st.session_state["show_download"] = False

                # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö save DB
                st.session_state["messages_gpt"] = base_messages + [
					{
						"role": "assistant",
						"content": result["reply"],
						"prompt_tokens": result["prompt_tokens"],
						"completion_tokens": result["completion_tokens"],
						"total_tokens": result["total_tokens"],
						"response_json": result["response_json"],
					}
				]

                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á SQLite
                save_conversation_if_ready(
					conn,
					cursor,
					messages_key="messages_gpt",         # ‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
					source=model_choice,                 # ‡πÄ‡∏ä‡πà‡∏ô "gpt-4o" ‡∏´‡∏£‡∏∑‡∏≠ "llama2:latest"
					prompt_tokens=result["prompt_tokens"],
					completion_tokens=result["completion_tokens"],
					total_tokens=result["total_tokens"],
				)

                if "conversation_title" not in st.session_state:
                    from utility_ai import generate_title_from_conversation

                    title = generate_title_from_conversation(
						st.session_state["messages_gpt"]
					)
                    st.session_state["conversation_title"] = title  # ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô UI
                    save_conversation_if_ready(
						cursor, title
					)  # ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤ DB
                    conn.commit()

            except Exception as e:
                st.error(f"‚ùå Error: {e}")

    # ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    show_download_section()

# ========== Choice 2: ‡πÄ‡∏û‡∏¥‡πà‡∏°/‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Prompt ==========
elif tab_choice == "üß† ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö Prompt":
    st.subheader("üß† ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö Prompt")

    tab_chat, tab_manage = st.tabs(["üí¨ Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ä‡∏ó‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ", "‚úçÔ∏è ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å / ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Prompt"])

    with tab_chat:
        st.caption("‡πÉ‡∏ä‡πâ Prompt ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö GPT ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡∏±‡∏Å‡∏ö‡∏±‡∏ç‡∏ä‡∏µ ‡∏ô‡∏±‡∏Å‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢")

        model_choice = st.radio(
			"üß† ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•",
			["gpt-4o", "gemma3:latest"],
			horizontal=True,
			key="model_selector_prompt",
		)

        prompts = list_prompts()
        prompt_dict = {name: content for name, content in prompts}

        if prompt_dict:
            selected_prompt_name = st.selectbox(
				"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Prompt", list(prompt_dict.keys()), key="prompt_selector"
			)
            selected_prompt = prompt_dict[selected_prompt_name]

            with st.expander("‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° Prompt ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"):
                st.code(selected_prompt)

            st.session_state.setdefault("chat_all_in_one", [])
            for msg in st.session_state["chat_all_in_one"]:
                st.chat_message(msg["role"]).write(msg["content"])

<<<<<<< HEAD
            with st.expander("üìÇ ‡∏Ç‡∏¢‡∏≤‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (txt, csv, xlsx)", expanded=False):
                uploaded_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (.txt, .csv, .xlsx) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Prompt", type=["txt", "csv", "xlsx"])
||||||| 1211786
            uploaded_file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (.txt, .csv, .xlsx) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Prompt", type=["txt", "csv", "xlsx"])
=======
            uploaded_file = st.file_uploader(
				"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (.txt, .csv, .xlsx) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Prompt",
				type=["txt", "csv", "xlsx"],
			)
>>>>>>> origin/dev_yok
            if uploaded_file:
                file_content = read_uploaded_file(uploaded_file.name, uploaded_file)
                st.session_state["file_content"] = file_content
                st.session_state["analysis_results"] = []
                st.session_state["uploaded_filename"] = uploaded_file.name
                st.caption(f"‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå: {uploaded_file.name}")
                st.text_area(
					"‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå", file_content[:3000], height=200, disabled=True
				)

            if st.button("üîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå‡∏î‡πâ‡∏ß‡∏¢ Prompt ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å"):
                try:
                    file_content = st.session_state.get("file_content", "")
                    full_input = f"‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:{selected_prompt} ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå:{file_content}"
                    system_prompt = "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ ‡πÄ‡∏ä‡πà‡∏ô ‡πÅ‡∏õ‡∏• ‡∏™‡∏£‡∏∏‡∏õ ‡∏ß‡∏¥‡πÄ‡∏£‡∏≤‡∏∞ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå"

                    base_messages = [
						{"role": "system", "content": system_prompt},
						{"role": "user", "content": full_input},
					]

                    with st.chat_message("assistant"):
                        stream_output = st.empty()
                        result = stream_response_by_model(
							model_choice, base_messages, stream_output
						)
                        stream_output.markdown(result["reply"])

                    reply = result["reply"]
                    raw_json = result["response_json"]
                    prompt_tokens = result["prompt_tokens"]
                    completion_tokens = result["completion_tokens"]
                    total_tokens = result["total_tokens"]

                    st.session_state["chat_all_in_one"].append(
						{"role": "assistant", "content": reply}
					)
                    st.session_state["analysis_result"] = reply
                    st.session_state["show_download"] = False

                    st.session_state["messages_gpt"] = base_messages + [
						{
							"role": "assistant",
							"content": reply,
							"prompt_tokens": prompt_tokens,
							"completion_tokens": completion_tokens,
							"total_tokens": total_tokens,
							"response_json": raw_json,
						}
					]
                    save_conversation_if_ready(
                        conn,
                        cursor,
                        messages_key="messages_prompt",  # ‚úÖ ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
                        source=model_choice,  # ‡πÄ‡∏ä‡πà‡∏ô "gpt-4o" ‡∏´‡∏£‡∏∑‡∏≠ "llama2:latest"
                        prompt_tokens=result["prompt_tokens"],
                        completion_tokens=result["completion_tokens"],
                        total_tokens=result["total_tokens"],
                    )

                except Exception as e:
                    st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")

            # ====== ‡∏Ñ‡∏∏‡∏¢‡∏ï‡πà‡∏≠ ======
            if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ß‡πà‡∏≤ '‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå')"):
                st.chat_message("user").write(prompt)
                st.session_state["chat_all_in_one"].append(
                    {"role": "user", "content": prompt}
                )

                if prompt.strip() == "‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå" or (
					"save" in prompt.lower() and st.session_state.get("analysis_result")
				):
                    st.chat_message("assistant").write("üì¶ ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
                    st.session_state["show_download"] = True
                else:
                    try:
                        file_content = st.session_state.get("file_content", "")
                        full_input = f"‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:{selected_prompt} ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°:{prompt} ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå:{file_content}"

                        base_messages = [
							{
								"role": "system",
								"content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏≤‡∏Å‡∏°‡∏µ",
							},
							{"role": "user", "content": full_input},
						]

                        with st.chat_message("assistant"):
                            stream_output = st.empty()
                            result = stream_response_by_model(
								model_choice, base_messages, stream_output
							)
                            stream_output.markdown(result["reply"])

                        reply = result["reply"]
                        raw_json = result["response_json"]
                        prompt_tokens = result["prompt_tokens"]
                        completion_tokens = result["completion_tokens"]
                        total_tokens = result["total_tokens"]

                        st.session_state["chat_all_in_one"].append(
							{"role": "assistant", "content": reply}
						)
                        st.session_state["analysis_result"] = reply
                        st.session_state["show_download"] = False

                        st.session_state["messages_gpt"] = base_messages + [
							{
								"role": "assistant",
								"content": reply,
								"prompt_tokens": prompt_tokens,
								"completion_tokens": completion_tokens,
								"total_tokens": total_tokens,
								"response_json": raw_json,
							}
						]
                        save_conversation_if_ready(
							conn,
							cursor,
							"messages_gpt",
							model_choice,
							prompt_tokens=prompt_tokens,
							completion_tokens=completion_tokens,
							total_tokens=total_tokens,
						)
                    except Exception as e:
                        st.error(f"Error: {e}")

            show_download_section()
        else:
            st.warning("‚ö†Ô∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ Prompt ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πá‡∏ö '‚ú® ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å / ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Prompt'")

    # ===== TAB 3: ‚úçÔ∏è ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å / ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Prompt =====
    with tab_manage:
        st.caption("‚úçÔ∏è ‡πÄ‡∏û‡∏¥‡πà‡∏° ‡∏•‡∏ö ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Prompt ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")

        # ===== ‡πÄ‡∏û‡∏¥‡πà‡∏° Prompt ‡πÉ‡∏´‡∏°‡πà =====
        prompt_name = st.text_input(
			"üìù ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠ Prompt ‡πÉ‡∏´‡∏°‡πà", key="prompt_name_input_create"
		)
        content = st.text_area(
			"üìÑ ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ Prompt", height=120, key="content_input_create"
		)
        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Prompt", key="save_prompt_create"):
            if prompt_name and content:
                save_prompt(prompt_name, content)
                st.success(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Prompt ‚Äú{prompt_name}‚Äù ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                st.toast("‚úÖ ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô", icon="‚úÖ")
                st.rerun()
            else:
                st.warning("‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ Prompt")

        # ===== ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Prompt ‡∏ó‡∏µ‡πà‡∏°‡∏µ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç/‡∏•‡∏ö =====
        prompts = list_prompts()
        if prompts:
            st.markdown("### üóÇ ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Prompt ‡∏ó‡∏µ‡πà‡∏°‡∏µ")
            for name, content in prompts:
                with st.expander(f"üìå {name}", expanded=False):
                    edited_content = st.text_area(
						"üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ Prompt",
						value=content,
						height=150,
						key=f"edit_{name}",
					)

                    col1, col2 = st.columns([1, 1])
                    with col1:
                        if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", key=f"save_edit_{name}"):
                            save_prompt(name, edited_content)
                            st.success(f"‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Prompt ‚Äú{name}‚Äù ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                            st.rerun()  # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏ô‡∏µ‡πâ‡πÅ‡∏ó‡∏ô experimental_rerun()

                    with col2:
                        if st.button("üóëÔ∏è ‡∏•‡∏ö Prompt ‡∏ô‡∏µ‡πâ", key=f"delete_prompt_{name}"):
                            delete_prompt(name)
                            st.success(f"‚úÖ ‡∏•‡∏ö‡πÅ‡∏•‡πâ‡∏ß: {name}")
                            st.rerun()  # ‚úÖ ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô
        else:
            st.info("‚ÑπÔ∏è ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ Prompt ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")

# ========== Choice 3: History ==========
elif tab_choice == "üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤":
    st.subheader("üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤")
    # =========== ‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏£‡∏≠‡∏Å user id   ===========
    user_id = st.session_state.get("user_id")
    role = st.session_state.get("Role", "").lower()

    if role in ["admin", "super admin"]:
        convs_all = list_conversations()
    else:
        convs_all = list_conversations(user_id)

    # ===== ‡πÄ‡∏û‡∏¥‡πà‡∏° filter ‡∏ï‡∏≤‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏• =====
    st.sidebar.markdown("### üéõÔ∏è ‡∏ï‡∏±‡∏ß‡∏Å‡∏£‡∏≠‡∏á")
    model_filter = st.sidebar.selectbox(
		"üì¶ ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•", ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"] + sorted(list(set(c[3] for c in convs_all)))
	)

    if model_filter != "‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î":
        convs = [c for c in convs_all if c[3] == model_filter]
    else:
        convs = convs_all

    if "messages_history" not in st.session_state:
        st.session_state["messages_history"] = []

    label_map = {
		f"{name} [{source}] ({created_at})": conv_id
		for conv_id, user_id, name, source, prompt_tokens, completion_tokens, total_tokens, created_at in convs
	}
    selected = st.selectbox("üìÅ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", ["- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å -"] + list(label_map.keys()))

    if selected != "- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å -":
        conv_id = label_map[selected]

        # ===== ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ä‡∏∑‡πà‡∏≠ =====
        title = selected.split(" [")[0]
        st.markdown(f"### üóÇÔ∏è ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: `{title}`")

        new_title = st.text_input(
			"‚úèÔ∏è ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", value=title, key="rename_title_input"
		)
        if new_title.strip() != title:
            cursor.execute(
				"UPDATE conversations SET title = ? WHERE id = ?",
				(new_title.strip(), conv_id),
			)
            conn.commit()
            st.success("‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
            st.rerun()

        cursor.execute(
			"""
			SELECT role, content, prompt_tokens, completion_tokens, total_tokens
			FROM messages
			WHERE conversation_id = ?
			ORDER BY id
			""",
			(conv_id,),
		)
        rows = cursor.fetchall()
        messages = [
			{
				"role": r,
				"content": c,
				"prompt_tokens": p,
				"completion_tokens": comp,
				"total_tokens": total,
			}
			for r, c, p, comp, total in rows
		]

        if (
			not st.session_state.get("messages_history")
			or st.session_state.get("conv_id") != conv_id
		):
            st.session_state["messages_history"] = messages
            st.session_state["conv_id"] = conv_id

        MAX_CHARS = 300
        PREVIEW_CHARS = 50  # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πá‡∏ô preview

        for msg in st.session_state.get("messages_history", []):
            role = msg.get("role", "user")
            content = msg.get("content", "").strip()

            with st.chat_message(role):
                if len(content) > MAX_CHARS:
                    preview = content[:PREVIEW_CHARS].rsplit(" ", 1)[0] + "..."  # ‡∏ï‡∏±‡∏î‡πÉ‡∏´‡πâ‡∏à‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥
                    st.markdown(preview)  # ‡πÅ‡∏™‡∏î‡∏á preview ‡∏î‡πâ‡∏≤‡∏ô‡∏ô‡∏≠‡∏Å

                    with st.expander("üìÑ ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"):
                        st.markdown(content)
                else:
                    st.markdown(content)

                if role == "assistant" and msg.get("total_tokens"):
                    st.caption(
						f"üî¢ Tokens: total={msg.get('total_tokens', 0)}, "
						f"prompt={msg.get('prompt_tokens', 0)}, "
						f"completion={msg.get('completion_tokens', 0)}"
					)

        model_choice = st.radio(
			"üßê ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡πÅ‡∏ä‡∏ó",
			["gpt-4o", "gemma3:latest"],
			horizontal=True,
			key="model_selector_history",
		)

        if prompt := st.chat_input(
			"üí¨ ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡πà‡∏≠‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤", key="chat_continue_input"
		):
            st.chat_message("user").write(prompt)
            st.session_state["messages_history"].append(
				{"role": "user", "content": prompt}
			)

            try:
                with st.chat_message("assistant"):
                    stream_output = st.empty()
                    result = stream_response_by_model(
						model_choice,
						st.session_state["messages_history"],
						stream_output,
					)
                    reply = result["reply"]
                    stream_output.markdown(reply)

                st.session_state["messages_history"].append(
					{
						"role": "assistant",
						"content": reply,
						"prompt_tokens": result["prompt_tokens"],
						"completion_tokens": result["completion_tokens"],
						"total_tokens": result["total_tokens"],
						"response_json": result["response_json"],
					}
				)

                save_conversation_if_ready(
					conn,
					cursor,
					messages_key="messages_history",
					source=model_choice,
					prompt_tokens=result["prompt_tokens"],
					completion_tokens=result["completion_tokens"],
					total_tokens=result["total_tokens"],
				)

            except Exception as e:
                st.error(f"‚ùå Error: {e}")

        with st.expander("üóëÔ∏è ‡∏•‡∏ö‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ô‡∏µ‡πâ"):
            if st.button("‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡∏ö", key="confirm_delete_conv"):
                cursor.execute(
					"DELETE FROM messages WHERE conversation_id = ?", (conv_id,)
				)
                cursor.execute("DELETE FROM conversations WHERE id = ?", (conv_id,))
                conn.commit()

                reset_on_button_click()
                st.success("‚úÖ ‡∏•‡∏ö‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
                st.rerun()

        if st.session_state.get("messages_history"):
            with st.expander("üìÖ ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå"):
                file_format = st.selectbox(
					"üìÑ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå",
					["txt", "md", "json", "csv"],
					key="history_download_format",
				)
                file_name = st.text_input(
					"üìù ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå", value="chat_history", key="history_download_filename"
				)

                full_filename = f"{file_name.strip()}.{file_format}"
                mime_type = "text/plain"
                content_lines = []
                file_bytes = StringIO()
                history = st.session_state["messages_history"]

                if file_format in ["txt", "md"]:
                    for msg in history:
                        role = msg.get("role", "unknown").capitalize()
                        text = msg.get("content", "").strip()
                        if not text:
                            continue
                        content_lines.append(
							f"**{role}:**\n{text}\n"
							if file_format == "md"
							else f"{role}:\n{text}\n"
						)
                        mime_type = (
							"text/markdown" if file_format == "md" else "text/plain"
						)
                    file_bytes.write("\n".join(content_lines))

                elif file_format == "json":
                    file_bytes.write(json.dumps(history, ensure_ascii=False, indent=2))
                    mime_type = "application/json"

                elif file_format == "csv":
                    pd.DataFrame(history).to_csv(
						file_bytes, index=False, encoding="utf-8-sig"
					)
                    mime_type = "text/csv"

                file_bytes.seek(0)
                st.download_button(
					label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå",
					data=file_bytes.getvalue(),
					file_name=full_filename,
					mime=mime_type,
				)

# ========== Choice 4 : ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ==========
if tab_choice == "üìò ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô":
	st.subheader("üìò ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
	tab_intro, tab_howto, tab_tip = st.tabs(
		["üß© ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°", "üí° ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Chatai", "üí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"]
	)

	with tab_intro:
		st.subheader("üß© ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
		st.markdown(
			"""
		‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö AI ‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Prompt ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏î‡πâ

		### üß± ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
		```plaintext
		ai_chat_platform/
		‚îú‚îÄ‚îÄ app.py                 # üéØ ‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å
		‚îú‚îÄ‚îÄ utility.py             # üß† ‡∏£‡∏ß‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
		‚îú‚îÄ‚îÄ .env                   # üîê ‡πÄ‡∏Å‡πá‡∏ö API Key ‡πÅ‡∏ö‡∏ö‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
		‚îú‚îÄ‚îÄ /pages/
		‚îÇ   ‚îú‚îÄ‚îÄ Chat_with_AI.py    # üí¨ ‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ä‡∏ó‡∏´‡∏•‡∏±‡∏Å
		‚îÇ   ‚îú‚îÄ‚îÄ History.py         # üìú ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
		‚îÇ   ‚îú‚îÄ‚îÄ Prompt_add.py      # üß† ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Prompt
		‚îú‚îÄ‚îÄ /data/
		‚îÇ   ‚îú‚îÄ‚îÄ sqdata.db          # üóÇ ‡πÑ‡∏ü‡∏•‡πå‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• SQLite
		‚îÇ   ‚îî‚îÄ‚îÄ schema.sql         # üìÑ ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
		
		üõ† ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö
		‚úÖ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö GPT-3.5/4 ‡πÑ‡∏î‡πâ‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
		‚úÖ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå .txt, .md, .csv ‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
		‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Prompt ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞
		‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å ‡πÅ‡∏•‡∏∞‡πÅ‡∏ä‡∏ó‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ
		‚úÖ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö LIFF ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏∑‡πà‡∏ô‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï
		"""
		)

	with tab_howto:
		st.subheader("üìù ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏°‡∏ô‡∏π")
		st.markdown(
			"""
		Chatai ‡∏ñ‡∏π‡∏Å‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏ú‡πà‡∏≤‡∏ô 4 ‡πÄ‡∏°‡∏ô‡∏π‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠ ‡πÇ‡∏î‡∏¢‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö GPT-3.5/4 ‡πÅ‡∏•‡∏∞‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ

		### 1Ô∏è‚É£  üí¨ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö GPT
		- ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (üìÑ ‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå)
		- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ñ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
		- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏õ‡∏∏‡πà‡∏° **"üÜï ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏ä‡∏ó‡πÉ‡∏´‡∏°‡πà"**
		- ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô‡∏Å‡∏•‡πà‡∏≠‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏≠‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å GPT
		- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏õ‡∏∏‡πà‡∏° **"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"**
		---
		### 2Ô∏è‚É£ ‡πÉ‡∏ä‡πâ Prompt ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á (üß† ‡πÄ‡∏û‡∏¥‡πà‡∏°/‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Prompt)
		- ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡∏≠‡∏á GPT (‡πÄ‡∏ä‡πà‡∏ô ‡∏ô‡∏±‡∏Å‡∏ö‡∏±‡∏ç‡∏ä‡∏µ, ‡∏ô‡∏±‡∏Å‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢, ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤ ‡∏Ø‡∏•‡∏Ø)
		- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Prompt ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
		- ‡πÅ‡∏ô‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ GPT ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö Prompt ‡∏Å‡πá‡πÑ‡∏î‡πâ
		- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Prompt ‡πÑ‡∏î‡πâ‡∏†‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏á
		---
		###3Ô∏è‚É£ ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ (üìú ‡πÅ‡∏ä‡∏ó‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏¥‡∏°)
		- ‡∏î‡∏π‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ
		- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤ > ‡πÅ‡∏ä‡∏ó‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
		- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï/‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ
		- **‡∏°‡∏µ‡∏õ‡∏∏‡πà‡∏°‡∏•‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
		---
		üí° **‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:** ‡∏ó‡∏∏‡∏Å‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ü‡∏£‡∏µ‡∏ú‡πà‡∏≤‡∏ô GPT-3.5 ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô GPT-4 (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ API Key ‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
		"""
		)
		with tab_tip:
			st.markdown(
				"""
		## üí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
		---
		### üß† ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt ‡πÅ‡∏ö‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏≤‡∏á
		‡πÄ‡∏ä‡πà‡∏ô:
		- ‚Äú‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏±‡∏Å‡∏ö‡∏±‡∏ç‡∏ä‡∏µ ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô‚Äù
		- ‚Äú‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ó‡∏ô‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏° ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢‚Äù
		‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô
		---
		### üìÇ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
		- ‡πÉ‡∏ä‡πâ `.txt` ‡∏´‡∏£‡∏∑‡∏≠ `.csv` ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‚Üí ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
		- ‡πÉ‡∏ä‡πâ `.xlsx` ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÅ‡∏ö‡∏ö Excel
		---
		### üÜï ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÅ‡∏ä‡∏ó‡πÉ‡∏´‡∏°‡πà
		- ‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ä‡∏ó, ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î, ‡∏ú‡∏•‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
		- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÉ‡∏´‡∏°‡πà, ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏°‡πà
		- ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå st.session_state ‡πÅ‡∏•‡∏∞ rerun
		---
		###üîÑ ‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä‡∏´‡∏ô‡πâ‡∏≤
		- ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà ‡πÇ‡∏î‡∏¢ ‡πÑ‡∏°‡πà‡∏•‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°
		- ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö: ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï UI ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
		- ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô: ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å st.experimental_rerun() ‡πÄ‡∏â‡∏¢ ‡πÜ
		---
		### üì• ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
		- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÉ‡∏ô‡∏ü‡∏≠‡∏£‡πå‡πÅ‡∏°‡∏ï‡∏ï‡πà‡∏≤‡∏á ‡πÜ:
		- `.txt` ‚Üí ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
		- `.md` ‚Üí ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Markdown
		- `.csv` ‚Üí ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏£‡∏≤‡∏á
		- `.xlsx` ‚Üí ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ô Excel
		---
		### üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÑ‡∏î‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥!
		- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡πÄ‡∏°‡∏ô‡∏π **üìú ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤**
		- ‡πÅ‡∏ä‡∏ó‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏î‡∏¥‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏î‡πâ
		---
		"""
			)

# Footer ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏™‡∏∏‡∏î
st.markdown(
	"""
	<hr style='margin-top: 3rem;'>
	<div style='text-align: center; color: gray;'>
		Provide ‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ‡∏ß‡∏¥‡∏•‡∏•‡πà‡∏≤ ‡∏°‡∏≤‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ï‡πÄ‡∏à‡∏û‡∏µ ‡πÇ‡∏î‡∏¢‡∏¢‡∏π‡∏ô‡∏¥‡∏Ñ‡∏≠‡∏£‡πå‡∏ô ‡πÄ‡∏ó‡∏Ñ ‡∏≠‡∏¥‡∏ô‡∏ó‡∏£‡∏¥‡πÄ‡∏Å‡∏£‡∏ä‡∏±‡πà‡∏ô
	</div>
""",
	unsafe_allow_html=True,
)
