from utility_ai import *

# ========== ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ ==========
st.title("ü§ñ ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡∏±‡∏ö AI ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ")

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•
model_choice = st.radio("üß† ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ", ["gpt-4o", "llama2:latest"], horizontal=True)

# ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå
uploaded_file = st.file_uploader("üìÇ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (txt, csv, xlsx)", type=["txt", "csv", "xlsx"])
if uploaded_file:
    try:
        file_content = read_uploaded_file(uploaded_file.name, uploaded_file)
        st.session_state["file_text"] = file_content
        st.text_area("üìÑ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå", file_content[:1000], height=200, disabled=True)
    except Exception as e:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏î‡πâ: {e}")
        st.stop()

# ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
file_content = st.session_state.get("file_text", "")
st.session_state.setdefault("chat_all_in_one", [])

# ‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á
for msg in st.session_state["chat_all_in_one"]:
    st.chat_message(msg["role"]).write(msg["content"])

# ‡∏ä‡πà‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
if prompt := st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ß‡πà‡∏≤ '‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå')"):
    st.chat_message("user").write(prompt)
    st.session_state["chat_all_in_one"].append({"role": "user", "content": prompt})

    if prompt.strip() == "‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå" or (
        "save" in prompt.lower() and st.session_state.get("analysis_result")
    ):
        st.chat_message("assistant").write("üì¶ ‡∏Ñ‡∏•‡∏¥‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå")
        st.session_state["show_download"] = True
    else:
        try:
            base_messages = [
                {
                    "role": "system",
                    "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏≤‡∏Å‡∏°‡∏µ",
                }
            ]
            if file_content:
                base_messages.append(
                    {"role": "user", "content": f"‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:\n{file_content}"}
                )
            base_messages.extend(st.session_state["chat_all_in_one"])

            with st.chat_message("assistant"):
                stream_output = st.empty()
                reply = stream_response_by_model(model_choice, base_messages, stream_output)
                stream_output.markdown(reply)

            # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î
            st.session_state["chat_all_in_one"].append({"role": "assistant", "content": reply})
            st.session_state["analysis_result"] = reply
            st.session_state["show_download"] = False

            # ‡∏ô‡∏±‡∏ö tokens
            prompt_tokens = sum(count_tokens(m["content"]) for m in base_messages)
            completion_tokens = count_tokens(reply)
            total_tokens = prompt_tokens + completion_tokens

            st.session_state["messages_gpt"] = base_messages + [
                {
                    "role": "assistant",
                    "content": reply,
                    "prompt_tokens": prompt_tokens,
                    "completion_tokens": completion_tokens,
                    "total_tokens": total_tokens,
                    "response_json": "{}",
                }
            ]
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å SQLite
            save_conversation_if_ready(
                conn,
                cursor,
                messages_key="messages_gpt",
                source="chat_gpt",
                prompt_tokens=prompt_tokens,
                completion_tokens=completion_tokens,
                total_tokens=total_tokens,
            )

        except Exception as e:
            st.error(f"‚ùå Error: {e}")

# ‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
show_download_section()

